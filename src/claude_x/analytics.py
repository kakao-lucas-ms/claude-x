"""Analytics module for prompt usage analysis."""

import json
import csv
from pathlib import Path
from typing import List, Dict, Optional
from datetime import datetime, timedelta
import sqlite3

from .storage import Storage


class PromptAnalytics:
    """Analyze prompt usage patterns."""

    def __init__(self, storage: Storage):
        """Initialize analytics.
        
        Args:
            storage: Storage instance
        """
        self.storage = storage

    def get_category_stats(self, project_name: str = "front") -> List[Dict]:
        """Get statistics by prompt category.
        
        Args:
            project_name: Project name to analyze
            
        Returns:
            List of category statistics
        """
        with self.storage._get_connection() as conn:
            cursor = conn.execute("""
                SELECT 
                    CASE 
                        WHEN lower(s.first_prompt) LIKE '%Î¶¨Î∑∞%' OR lower(s.first_prompt) LIKE '%review%' THEN 'ÏΩîÎìú Î¶¨Î∑∞'
                        WHEN lower(s.first_prompt) LIKE '%ÌÖåÏä§Ìä∏%' OR lower(s.first_prompt) LIKE '%test%' THEN 'ÌÖåÏä§Ìä∏'
                        WHEN lower(s.first_prompt) LIKE '%Î≤ÑÍ∑∏%' OR lower(s.first_prompt) LIKE '%bug%' OR lower(s.first_prompt) LIKE '%fix%' THEN 'Î≤ÑÍ∑∏ ÏàòÏ†ï'
                        WHEN lower(s.first_prompt) LIKE '%Íµ¨ÌòÑ%' OR lower(s.first_prompt) LIKE '%implement%' OR lower(s.first_prompt) LIKE '%add%' THEN 'Í∏∞Îä• Íµ¨ÌòÑ'
                        WHEN lower(s.first_prompt) LIKE '%Î¶¨Ìå©ÌÜ†ÎßÅ%' OR lower(s.first_prompt) LIKE '%refactor%' THEN 'Î¶¨Ìå©ÌÜ†ÎßÅ'
                        WHEN lower(s.first_prompt) LIKE '%Î¨∏ÏÑú%' OR lower(s.first_prompt) LIKE '%doc%' THEN 'Î¨∏ÏÑúÌôî'
                        ELSE 'Í∏∞ÌÉÄ'
                    END as category,
                    COUNT(DISTINCT s.session_id) as session_count,
                    COUNT(DISTINCT m.id) as total_messages,
                    COUNT(DISTINCT CASE WHEN m.type = 'user' THEN m.id END) as user_prompts,
                    COUNT(DISTINCT cs.id) as code_count,
                    ROUND(AVG(s.message_count), 1) as avg_messages_per_session,
                    ROUND(CAST(COUNT(DISTINCT cs.id) AS FLOAT) / NULLIF(COUNT(DISTINCT s.session_id), 0), 1) as avg_code_per_session
                FROM sessions s
                JOIN projects p ON s.project_id = p.id
                LEFT JOIN messages m ON s.session_id = m.session_id
                LEFT JOIN code_snippets cs ON m.id = cs.message_id
                WHERE p.name = ?
                GROUP BY category
                ORDER BY session_count DESC
            """, (project_name,))
            return [dict(row) for row in cursor.fetchall()]

    def get_branch_productivity(self, project_name: str = "front") -> List[Dict]:
        """Get productivity metrics by branch type.
        
        Args:
            project_name: Project name to analyze
            
        Returns:
            List of branch productivity metrics
        """
        with self.storage._get_connection() as conn:
            cursor = conn.execute("""
                SELECT 
                    CASE 
                        WHEN s.git_branch LIKE 'feature/%' THEN 'Feature'
                        WHEN s.git_branch LIKE 'hotfix/%' THEN 'Hotfix'
                        WHEN s.git_branch = 'dev' THEN 'Dev'
                        WHEN s.git_branch = 'main' OR s.git_branch = 'master' THEN 'Main'
                        ELSE 'Other'
                    END as branch_type,
                    COUNT(DISTINCT s.session_id) as session_count,
                    COUNT(DISTINCT m.id) as total_messages,
                    COUNT(DISTINCT cs.id) as code_count,
                    ROUND(CAST(COUNT(DISTINCT cs.id) AS FLOAT) / NULLIF(COUNT(DISTINCT m.id), 0), 2) as code_per_message_ratio,
                    ROUND(AVG(s.message_count), 1) as avg_messages_per_session
                FROM sessions s
                JOIN projects p ON s.project_id = p.id
                LEFT JOIN messages m ON s.session_id = m.session_id
                LEFT JOIN code_snippets cs ON m.id = cs.message_id
                WHERE p.name = ?
                GROUP BY branch_type
                ORDER BY session_count DESC
            """, (project_name,))
            return [dict(row) for row in cursor.fetchall()]

    def get_language_distribution(self, project_name: str = "front") -> List[Dict]:
        """Get code language distribution.
        
        Args:
            project_name: Project name to analyze
            
        Returns:
            List of language statistics
        """
        with self.storage._get_connection() as conn:
            cursor = conn.execute("""
                SELECT 
                    cs.language,
                    COUNT(*) as count,
                    ROUND(CAST(COUNT(*) AS FLOAT) * 100.0 / (
                        SELECT COUNT(*) 
                        FROM code_snippets cs2
                        JOIN sessions s2 ON cs2.session_id = s2.session_id
                        JOIN projects p2 ON s2.project_id = p2.id
                        WHERE p2.name = ?
                    ), 2) as percentage,
                    SUM(cs.line_count) as total_lines
                FROM code_snippets cs
                JOIN sessions s ON cs.session_id = s.session_id
                JOIN projects p ON s.project_id = p.id
                WHERE p.name = ?
                GROUP BY cs.language
                ORDER BY count DESC
                LIMIT 15
            """, (project_name, project_name))
            return [dict(row) for row in cursor.fetchall()]

    def get_time_based_analysis(self, project_name: str = "front", days: int = 30) -> Dict:
        """Get time-based usage analysis.
        
        Args:
            project_name: Project name to analyze
            days: Number of days to analyze
            
        Returns:
            Time-based statistics
        """
        with self.storage._get_connection() as conn:
            # Daily activity
            cursor = conn.execute("""
                SELECT 
                    DATE(s.created_at) as date,
                    COUNT(DISTINCT s.session_id) as sessions,
                    COUNT(DISTINCT m.id) as messages,
                    COUNT(DISTINCT cs.id) as code_snippets
                FROM sessions s
                JOIN projects p ON s.project_id = p.id
                LEFT JOIN messages m ON s.session_id = m.session_id
                LEFT JOIN code_snippets cs ON m.id = cs.message_id
                WHERE p.name = ? 
                    AND s.created_at >= datetime('now', '-' || ? || ' days')
                GROUP BY DATE(s.created_at)
                ORDER BY date DESC
            """, (project_name, days))
            daily_activity = [dict(row) for row in cursor.fetchall()]

            # Hour distribution
            cursor = conn.execute("""
                SELECT 
                    CAST(strftime('%H', s.created_at) AS INTEGER) as hour,
                    COUNT(DISTINCT s.session_id) as sessions
                FROM sessions s
                JOIN projects p ON s.project_id = p.id
                WHERE p.name = ?
                GROUP BY hour
                ORDER BY sessions DESC
            """, (project_name,))
            hour_distribution = [dict(row) for row in cursor.fetchall()]

            # Most productive day
            cursor = conn.execute("""
                SELECT 
                    DATE(s.created_at) as date,
                    COUNT(DISTINCT cs.id) as code_count
                FROM sessions s
                JOIN projects p ON s.project_id = p.id
                LEFT JOIN messages m ON s.session_id = m.session_id
                LEFT JOIN code_snippets cs ON m.id = cs.message_id
                WHERE p.name = ?
                GROUP BY DATE(s.created_at)
                ORDER BY code_count DESC
                LIMIT 1
            """, (project_name,))
            most_productive = cursor.fetchone()

            return {
                "daily_activity": daily_activity,
                "hour_distribution": hour_distribution,
                "most_productive_day": dict(most_productive) if most_productive else None
            }

    def get_top_sessions(self, project_name: str = "front", limit: int = 10) -> List[Dict]:
        """Get most active sessions.
        
        Args:
            project_name: Project name to analyze
            limit: Max results
            
        Returns:
            List of top sessions
        """
        with self.storage._get_connection() as conn:
            cursor = conn.execute("""
                SELECT 
                    s.session_id,
                    s.first_prompt,
                    s.git_branch,
                    s.created_at,
                    COUNT(DISTINCT m.id) as message_count,
                    COUNT(DISTINCT cs.id) as code_count,
                    GROUP_CONCAT(DISTINCT cs.language) as languages
                FROM sessions s
                JOIN projects p ON s.project_id = p.id
                LEFT JOIN messages m ON s.session_id = m.session_id
                LEFT JOIN code_snippets cs ON m.id = cs.message_id
                WHERE p.name = ?
                GROUP BY s.session_id
                ORDER BY message_count DESC
                LIMIT ?
            """, (project_name, limit))
            return [dict(row) for row in cursor.fetchall()]

    def get_sensitive_data_report(self, project_name: str = "front") -> Dict:
        """Get sensitive data detection report.
        
        Args:
            project_name: Project name to analyze
            
        Returns:
            Sensitive data statistics
        """
        with self.storage._get_connection() as conn:
            cursor = conn.execute("""
                SELECT 
                    COUNT(*) as total_snippets,
                    COUNT(CASE WHEN has_sensitive THEN 1 END) as sensitive_count,
                    ROUND(CAST(COUNT(CASE WHEN has_sensitive THEN 1 END) AS FLOAT) * 100.0 / COUNT(*), 2) as sensitive_percentage
                FROM code_snippets cs
                JOIN sessions s ON cs.session_id = s.session_id
                JOIN projects p ON s.project_id = p.id
                WHERE p.name = ?
            """, (project_name,))
            stats = dict(cursor.fetchone())

            # Get sessions with sensitive data
            cursor = conn.execute("""
                SELECT DISTINCT
                    s.session_id,
                    s.first_prompt,
                    s.git_branch,
                    COUNT(DISTINCT cs.id) as sensitive_snippet_count
                FROM sessions s
                JOIN projects p ON s.project_id = p.id
                JOIN messages m ON s.session_id = m.session_id
                JOIN code_snippets cs ON m.id = cs.message_id
                WHERE p.name = ? AND cs.has_sensitive = 1
                GROUP BY s.session_id
                ORDER BY sensitive_snippet_count DESC
            """, (project_name,))
            sensitive_sessions = [dict(row) for row in cursor.fetchall()]

            return {
                "statistics": stats,
                "affected_sessions": sensitive_sessions
            }

    def export_to_json(self, data: Dict, output_path: Path):
        """Export analytics data to JSON.
        
        Args:
            data: Data to export
            output_path: Output file path
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False, default=str)

    def export_to_csv(self, data: List[Dict], output_path: Path):
        """Export analytics data to CSV.
        
        Args:
            data: Data to export (list of dicts)
            output_path: Output file path
        """
        if not data:
            return

        with open(output_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=data[0].keys())
            writer.writeheader()
            writer.writerows(data)

    def analyze_prompt_quality(self, project_name: str = "front") -> List[Dict]:
        """Analyze prompt quality with scoring.

        Args:
            project_name: Project name to analyze

        Returns:
            List of prompts with quality scores
        """
        with self.storage._get_connection() as conn:
            cursor = conn.execute("""
                WITH session_metrics AS (
                    SELECT
                        s.session_id,
                        s.first_prompt,
                        s.git_branch,
                        s.created_at,
                        COUNT(DISTINCT m.id) as message_count,
                        COUNT(DISTINCT CASE WHEN m.type = 'user' THEN m.id END) as user_prompt_count,
                        COUNT(DISTINCT cs.id) as code_count,
                        SUM(cs.line_count) as total_lines,
                        COUNT(DISTINCT cs.language) as language_diversity,
                        COUNT(DISTINCT CASE WHEN cs.has_sensitive THEN cs.id END) as sensitive_count,
                        CASE
                            WHEN lower(s.first_prompt) LIKE '%Î¶¨Î∑∞%' OR lower(s.first_prompt) LIKE '%review%' THEN 'ÏΩîÎìú Î¶¨Î∑∞'
                            WHEN lower(s.first_prompt) LIKE '%ÌÖåÏä§Ìä∏%' OR lower(s.first_prompt) LIKE '%test%' THEN 'ÌÖåÏä§Ìä∏'
                            WHEN lower(s.first_prompt) LIKE '%Î≤ÑÍ∑∏%' OR lower(s.first_prompt) LIKE '%bug%' OR lower(s.first_prompt) LIKE '%fix%' THEN 'Î≤ÑÍ∑∏ ÏàòÏ†ï'
                            WHEN lower(s.first_prompt) LIKE '%Íµ¨ÌòÑ%' OR lower(s.first_prompt) LIKE '%implement%' OR lower(s.first_prompt) LIKE '%add%' THEN 'Í∏∞Îä• Íµ¨ÌòÑ'
                            WHEN lower(s.first_prompt) LIKE '%Î¶¨Ìå©ÌÜ†ÎßÅ%' OR lower(s.first_prompt) LIKE '%refactor%' THEN 'Î¶¨Ìå©ÌÜ†ÎßÅ'
                            ELSE 'Í∏∞ÌÉÄ'
                        END as category
                    FROM sessions s
                    JOIN projects p ON s.project_id = p.id
                    LEFT JOIN messages m ON s.session_id = m.session_id
                    LEFT JOIN code_snippets cs ON m.id = cs.message_id
                    WHERE p.name = ?
                    GROUP BY s.session_id
                    HAVING code_count > 0
                )
                SELECT
                    session_id,
                    first_prompt,
                    git_branch,
                    created_at,
                    category,
                    message_count,
                    user_prompt_count,
                    code_count,
                    total_lines,
                    language_diversity,
                    sensitive_count,
                    -- Efficiency: ÏΩîÎìú ÏÉùÏÑ±Îüâ / ÏÇ¨Ïö©Ïûê ÌîÑÎ°¨ÌîÑÌä∏ Ïàò
                    ROUND(CAST(code_count AS FLOAT) / NULLIF(user_prompt_count, 0), 2) as efficiency_score,
                    -- Clarity: ÏßßÏùÄ ÎåÄÌôîÏùºÏàòÎ°ù Î™ÖÌôïÌïú ÌîÑÎ°¨ÌîÑÌä∏ (Ï†ïÍ∑úÌôî: 1 / log(messages))
                    ROUND(100.0 / NULLIF(message_count, 0), 2) as clarity_score,
                    -- Productivity: Ï¥ù ÏÉùÏÑ± ÎùºÏù∏ Ïàò (ÏÉÅÏúÑ 20%Î©¥ ÎÜíÏùÄ Ï†êÏàò)
                    total_lines as productivity_score,
                    -- Quality: ÎØºÍ∞ê Ï†ïÎ≥¥ ÏóÜÍ≥† Ïñ∏Ïñ¥ Îã§ÏñëÏÑ± ÎÜíÏúºÎ©¥ Ï¢ãÏùå
                    CASE
                        WHEN sensitive_count = 0 AND language_diversity >= 3 THEN 10
                        WHEN sensitive_count = 0 AND language_diversity >= 2 THEN 8
                        WHEN sensitive_count = 0 THEN 6
                        WHEN language_diversity >= 3 THEN 5
                        ELSE 3
                    END as quality_score
                FROM session_metrics
            """, (project_name,))

            results = [dict(row) for row in cursor.fetchall()]

            # Calculate composite score (weighted average)
            for r in results:
                # Normalize productivity score (0-10 scale)
                max_lines = max([x['total_lines'] or 0 for x in results])
                normalized_productivity = (r['productivity_score'] or 0) / max(max_lines, 1) * 10

                # Composite score: efficiency 40%, clarity 30%, productivity 20%, quality 10%
                r['composite_score'] = round(
                    (r['efficiency_score'] or 0) * 0.4 +
                    (r['clarity_score'] or 0) * 0.3 +
                    normalized_productivity * 0.2 +
                    r['quality_score'] * 0.1,
                    2
                )

            return sorted(results, key=lambda x: x['composite_score'], reverse=True)

    def get_best_prompts(self, project_name: str = "front", limit: int = 10) -> List[Dict]:
        """Get best performing prompts.

        Args:
            project_name: Project name to analyze
            limit: Number of top prompts

        Returns:
            List of best prompts with scores
        """
        all_prompts = self.analyze_prompt_quality(project_name)
        return all_prompts[:limit]

    def get_worst_prompts(self, project_name: str = "front", limit: int = 10) -> List[Dict]:
        """Get worst performing prompts.

        Args:
            project_name: Project name to analyze
            limit: Number of bottom prompts

        Returns:
            List of worst prompts with scores
        """
        all_prompts = self.analyze_prompt_quality(project_name)
        return all_prompts[-limit:][::-1]  # Reverse to show worst first

    def export_prompt_library(self, project_name: str = "front", output_path: Path = None):
        """Export prompt library as markdown.

        Args:
            project_name: Project name to analyze
            output_path: Output file path
        """
        if output_path is None:
            output_path = Path.home() / ".claude-x" / "prompt-library" / f"{project_name}-prompts.md"

        output_path.parent.mkdir(parents=True, exist_ok=True)

        best = self.get_best_prompts(project_name, 15)
        worst = self.get_worst_prompts(project_name, 10)

        # Group by category
        by_category = {}
        for prompt in best:
            cat = prompt['category']
            if cat not in by_category:
                by_category[cat] = []
            by_category[cat].append(prompt)

        lines = [
            f"# ÌîÑÎ°¨ÌîÑÌä∏ ÎùºÏù¥Î∏åÎü¨Î¶¨: {project_name}",
            f"",
            f"ÏÉùÏÑ±Ïùº: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
            f"Ï¥ù Î∂ÑÏÑù ÌîÑÎ°¨ÌîÑÌä∏: {len(self.analyze_prompt_quality(project_name))}Í∞ú",
            f"",
            "---",
            "",
            "## üìä Ï†êÏàò Í≥ÑÏÇ∞ Î∞©Ïãù",
            "",
            "Í∞Å ÌîÑÎ°¨ÌîÑÌä∏Îäî Îã§Ïùå 4Í∞ÄÏßÄ ÏßÄÌëúÎ°ú ÌèâÍ∞ÄÎê©ÎãàÎã§:",
            "",
            "- **Ìö®Ïú®ÏÑ± (40%)**: ÏΩîÎìú ÏÉùÏÑ±Îüâ / ÌîÑÎ°¨ÌîÑÌä∏ Ïàò",
            "- **Î™ÖÌôïÏÑ± (30%)**: ÏßßÏùÄ ÎåÄÌôîÎ°ú Î™©Ìëú Îã¨ÏÑ± (Î©îÏãúÏßÄ ÏàòÏùò Ïó≠Ïàò)",
            "- **ÏÉùÏÇ∞ÏÑ± (20%)**: Ï¥ù ÏÉùÏÑ± ÏΩîÎìú ÎùºÏù∏ Ïàò",
            "- **ÌíàÏßà (10%)**: ÎØºÍ∞ê Ï†ïÎ≥¥ ÏóÜÏùå + Ïñ∏Ïñ¥ Îã§ÏñëÏÑ±",
            "",
            "**Ï¢ÖÌï© Ï†êÏàò = Ìö®Ïú®ÏÑ±√ó0.4 + Î™ÖÌôïÏÑ±√ó0.3 + ÏÉùÏÇ∞ÏÑ±√ó0.2 + ÌíàÏßà√ó0.1**",
            "",
            "---",
            "",
            "## üèÜ Î≤†Ïä§Ìä∏ ÌîÑÎ°¨ÌîÑÌä∏ (Top 15)",
            "",
            "ÏÑ±Í≥µÏ†ÅÏù∏ ÌîÑÎ°¨ÌîÑÌä∏ Ìå®ÌÑ¥ÏùÑ ÌïôÏäµÌïòÏÑ∏Ïöî.",
            ""
        ]

        for i, prompt in enumerate(best, 1):
            lines.extend([
                f"### {i}. {prompt['category']} (Ï†êÏàò: {prompt['composite_score']})",
                f"",
                f"**ÌîÑÎ°¨ÌîÑÌä∏:**",
                f"> {prompt['first_prompt'][:200]}{'...' if len(prompt['first_prompt']) > 200 else ''}",
                f"",
                f"**ÏÑ∏ÏÖò Ï†ïÎ≥¥:**",
                f"- ÏÑ∏ÏÖò ID: `{prompt['session_id'][:16]}...`",
                f"- Î∏åÎûúÏπò: `{prompt['git_branch'] or 'N/A'}`",
                f"- ÎÇ†Ïßú: {prompt['created_at'][:10] if prompt['created_at'] else 'N/A'}",
                f"",
                f"**ÏÑ±Í≥º ÏßÄÌëú:**",
                f"- Ï¥ù Î©îÏãúÏßÄ: {prompt['message_count']}Í∞ú",
                f"- ÏÇ¨Ïö©Ïûê ÌîÑÎ°¨ÌîÑÌä∏: {prompt['user_prompt_count']}Í∞ú",
                f"- ÏÉùÏÑ± ÏΩîÎìú: {prompt['code_count']}Í∞ú ({prompt['total_lines']}Ï§Ñ)",
                f"- ÏÇ¨Ïö© Ïñ∏Ïñ¥: {prompt['language_diversity']}Ï¢ÖÎ•ò",
                f"",
                f"**Ï†êÏàò Î∂ÑÏÑù:**",
                f"- Ìö®Ïú®ÏÑ±: {prompt['efficiency_score']} (ÏΩîÎìú/ÌîÑÎ°¨ÌîÑÌä∏)",
                f"- Î™ÖÌôïÏÑ±: {prompt['clarity_score']}",
                f"- ÏÉùÏÇ∞ÏÑ±: {prompt['total_lines']}Ï§Ñ",
                f"- ÌíàÏßà: {prompt['quality_score']}/10",
                f"",
                "---",
                ""
            ])

        lines.extend([
            "",
            "## üìö Ïπ¥ÌÖåÍ≥†Î¶¨Î≥Ñ Î≤†Ïä§Ìä∏ ÌîÑÎ°¨ÌîÑÌä∏",
            ""
        ])

        for category, prompts in sorted(by_category.items()):
            lines.extend([
                f"### {category}",
                ""
            ])
            for p in prompts[:3]:  # Top 3 per category
                lines.extend([
                    f"- **Ï†êÏàò {p['composite_score']}**: {p['first_prompt'][:100]}...",
                    f"  - üíª ÏΩîÎìú {p['code_count']}Í∞ú, üìù {p['total_lines']}Ï§Ñ, üí¨ Î©îÏãúÏßÄ {p['message_count']}Í∞ú",
                    ""
                ])
            lines.append("")

        lines.extend([
            "## ‚ö†Ô∏è Í∞úÏÑ†Ïù¥ ÌïÑÏöîÌïú ÌîÑÎ°¨ÌîÑÌä∏ (Bottom 10)",
            "",
            "Îã§Ïùå Ìå®ÌÑ¥ÏùÄ ÌîºÌïòÎäî Í≤ÉÏù¥ Ï¢ãÏäµÎãàÎã§.",
            ""
        ])

        for i, prompt in enumerate(worst, 1):
            lines.extend([
                f"### {i}. {prompt['category']} (Ï†êÏàò: {prompt['composite_score']})",
                f"",
                f"**ÌîÑÎ°¨ÌîÑÌä∏:**",
                f"> {prompt['first_prompt'][:200]}{'...' if len(prompt['first_prompt']) > 200 else ''}",
                f"",
                f"**Î¨∏Ï†úÏ†ê:**",
            ])

            issues = []
            if prompt['efficiency_score'] < 1:
                issues.append("- ÎÇÆÏùÄ Ìö®Ïú®ÏÑ±: ÌîÑÎ°¨ÌîÑÌä∏Îãπ ÏÉùÏÑ±Îêú ÏΩîÎìúÍ∞Ä Ï†ÅÏùå")
            if prompt['message_count'] > 100:
                issues.append("- Í∏¥ ÎåÄÌôî: Î™ÖÌôïÌïòÏßÄ ÏïäÏùÄ ÏßÄÏãúÎ°ú ÎßéÏùÄ ÎåÄÌôî ÌïÑÏöî")
            if prompt['sensitive_count'] > 0:
                issues.append(f"- Î≥¥Ïïà Ïù¥Ïäà: ÎØºÍ∞ê Ï†ïÎ≥¥ {prompt['sensitive_count']}Í±¥ Î∞úÍ≤¨")
            if prompt['language_diversity'] < 2:
                issues.append("- Ï†úÌïúÏ†ÅÏù∏ ÏÇ∞Ï∂úÎ¨º: Îã®Ïùº Ïñ∏Ïñ¥Îßå ÏÇ¨Ïö©")

            if not issues:
                issues.append("- Ï†ÑÎ∞òÏ†ÅÏúºÎ°ú ÎÇÆÏùÄ ÏÑ±Í≥º ÏßÄÌëú")

            lines.extend(issues)
            lines.extend([
                f"",
                f"**Í∞úÏÑ† Î∞©Ìñ•:**",
                f"- Îçî Íµ¨Ï≤¥Ï†ÅÏù∏ ÏöîÍµ¨ÏÇ¨Ìï≠ Î™ÖÏãú",
                f"- ÏòàÏÉÅ Í≤∞Í≥ºÎ¨º ÌòïÌÉú Ï†úÏãú",
                f"- Îã®Í≥ÑÎ≥ÑÎ°ú ÏûëÏóÖ Î∂ÑÎ¶¨",
                "",
                "---",
                ""
            ])

        lines.extend([
            "",
            "## üí° ÌîÑÎ°¨ÌîÑÌä∏ ÏûëÏÑ± ÌåÅ",
            "",
            "Î≤†Ïä§Ìä∏ ÌîÑÎ°¨ÌîÑÌä∏ Î∂ÑÏÑù Í≤∞Í≥ºÎ•º Î∞îÌÉïÏúºÎ°ú Ìïú Í∂åÏû•ÏÇ¨Ìï≠:",
            "",
            "1. **Î™ÖÌôïÌïú Î™©Ìëú ÏÑ§Ï†ï**: Î¨¥ÏóáÏùÑ ÎßåÎì§Í≥† Ïã∂ÏùÄÏßÄ Íµ¨Ï≤¥Ï†ÅÏúºÎ°ú Î™ÖÏãú",
            "2. **Ïª®ÌÖçÏä§Ìä∏ Ï†úÍ≥µ**: ÌòÑÏû¨ ÏÉÅÌô©Í≥º Î∞∞Í≤Ω ÏÑ§Î™Ö",
            "3. **ÏòàÏãú Ï†úÍ≥µ**: ÏõêÌïòÎäî Í≤∞Í≥ºÎ¨ºÏùò ÏòàÏãúÎÇò Ï∞∏Í≥† ÏûêÎ£å",
            "4. **Ï†úÏïΩÏÇ¨Ìï≠ Î™ÖÏãú**: ÏßÄÏºúÏïº Ìï† Í∑úÏπôÏù¥ÎÇò Ï†úÌïúÏÇ¨Ìï≠",
            "5. **Îã®Í≥ÑÏ†Å Ï†ëÍ∑º**: ÌÅ∞ ÏûëÏóÖÏùÄ ÏûëÏùÄ Îã®ÏúÑÎ°ú Î∂ÑÎ¶¨",
            "",
            "---",
            "",
            f"üìù Ïù¥ Î¨∏ÏÑúÎäî `cx prompts --project {project_name} --export` Î™ÖÎ†πÏúºÎ°ú ÏÉùÏÑ±ÎêòÏóàÏäµÎãàÎã§.",
            ""
        ])

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))

        return output_path

    def generate_full_report(self, project_name: str = "front") -> Dict:
        """Generate comprehensive analytics report.

        Args:
            project_name: Project name to analyze

        Returns:
            Complete analytics report
        """
        return {
            "project": project_name,
            "generated_at": datetime.now().isoformat(),
            "category_stats": self.get_category_stats(project_name),
            "branch_productivity": self.get_branch_productivity(project_name),
            "language_distribution": self.get_language_distribution(project_name),
            "time_analysis": self.get_time_based_analysis(project_name),
            "top_sessions": self.get_top_sessions(project_name),
            "sensitive_data": self.get_sensitive_data_report(project_name)
        }
